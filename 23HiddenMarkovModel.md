# 隐马尔科夫模型

##一、基本概念

###1.1 马尔科夫链

​        在随机过程中，如果离散型随机变量 $\{C_t:t \in N\}$对于所有 $t \in N$，满足以下的**马尔科夫性质**：
$$
Pr(C_{t+1}|C_t,...,C_1)=Pr(C_{t+1}|C_t)
$$
则称之为（离散时间）马尔科夫链。

​        与马尔科夫链相关的一个重要量是**转移概率**：$Pr(C_{s+t}=j|C_s=i)$，如果转移概率不依赖于 $s$，马尔科夫链被称为**齐次**，后文讨论的马尔科夫链都将是齐次的。



###1.2 隐马尔科夫模型

​        隐马尔科夫模型（hiden Markov model，**HMM**）是指”观察结果的分布依赖于一个潜在的、未观察到的马尔科夫链“的模型。

​        下面定义隐马尔科夫模型的相关符号，它们会频繁在后文出现。

​        $S=\{S_t\}(t=1,2,...,T)$：隐马尔科夫过程.

​        $T$：观测序列的长度.

​        $s=\{s_i\}，i=1,2,...,m$：隐马尔科夫链的状态空间.

​        $m$：状态空间的元素个数.

​        $O=\{O_t\}$：观测值序列.

​        $V=\{v_i\}，i=1,2,...,n$：$O_i$的所有可能取值.

​        $n$：$V$的元素个数.

​        $A(m*m)$：隐马尔科夫链的状态概率转移矩阵，其元素$a_{ij}$表示状态$s_i$下一时刻变为$s_j$的概率.

​        $B(m*n)$：发送概率矩阵，其元素$b_{s_i}(O_j)$表示隐状态$s_i$表现为观测值$O_j$的概率.

​        $\pi=\{\pi_i\}$：隐马尔科夫链的初始状态分布概率，其元素 $\pi_i$ 表示$P(S_1=s_i)$.

​        隐马尔科夫模型的示意图如下所示：

![隐马尔科夫模型](C:\Users\Pine1968\Desktop\贝叶斯分析\隐马尔科夫模型.png)



​        该模型由两部分组成：①可观测的过程$O_t$.

​                                               ②一个未观测到的满足马尔科夫属性的过程${S_t}$，$O_t$依赖于该过程，可以将该过程理解为$O_t$的“参数过程”；

因此，当$S_t$已知时，$O_t$的分布只取决于当前的隐状态$S_t$，而不是该时刻之前的任何隐状态或观测结果。  需要注意的是，满足马尔科夫性质的是 $S_t$，$O_t$过程是**不一定**满足马尔科夫性质的。

隐马尔科夫模型由 $A,B,\pi$ 三个要素确定,因此一般模型$M$可以表示为：
$$
M = (A,B,\pi)
$$



## 二、HMM的三个主要问题

### 1.评估问题

​        定义：给定隐马尔科夫模型$M = (A,B,\pi)$ 和观测值序列 $O=\{O_i\}$ ，计算在模型 $M$ 下 观测值序列 $O$ 出现的概率 $P(O|M)$。

​        最直观的想法是用穷举法解决这个问题，即列出每一个隐藏状态序列$S$，计算其产生观测序列$O$的概率并求和。然而，对于长度较大、状态空间较大的马尔科夫链，直接计算条件概率过于复杂。一般地，采用前向算法或后向算法来解决评估问题。

#### 1.1前向算法

​        定义**前向概率**为到时刻 $t$ 时观测序列 $O_1,O_2,...,O_t$ 出现且此时隐藏状态为 $s_i$ 的概率，即：
$$
\alpha_t(i)=P(O_1,O_2,...,O_t,S_t=s_i|M).
$$
$\alpha_t(i)$可以进行如下迭代计算：

​        对于$t=1$，以及 $i=1,2,..,m$，$\alpha_1(i)=\pi_ib_i(O_1)$.

​        对于 $t=2,3,..,T$ 以及 $i=1,2,...,n$，
$$
\alpha_t(i)=[\sum_{j=1}^n{\alpha_{t-1}(j)}]a_{ji}b_i(O_t)
$$
​        模型 $m$ 下观测序列 $O$ 的出现概率可以表示为：
$$
P(O|M)=\sum_{i=1}^n\alpha_T(i).
$$
​      从上述推导可以看出，该算法的好处在于，把观测序列出现的**条件概率**，等价为隐藏状态和观测序列的出现的**联合概率**。这样做的好处是：联合概率可以结合初始分布$\pi$、转移概率$A$和发送概率$B$迭代得出，大大简化了计算，所以该方法所用时间明显低于穷举法。  



####1.2后向算法

​        后向算法与前向算法的相同之处在于，也将观测序列的条件概率转换为联合概率；不同之处则在于迭代方向，后向算法以观测序列的末端为出发点，向首端迭代。

​        定义**后向概率**为到时刻 $t$ 时隐藏状态为 $S_i$，且 $t+1$ 到 $T$ 时刻的观测序列为 $O_{t+1},O_{t+2},...,O_T$ 的概率，即：
$$
\beta_t(i)=P(O_{t+1},O_{t+2},...,O_T,S_t=s_i|M).
$$
$\beta_t(i)$的迭代从最后时刻开始向前一时刻。

​        对于$t=T$ 以及 $i=1,2,...,m$，由于实际不存在 $T+1$ 时刻，定义 $\beta_{T}(i)=1$，相当于把 $T$ 时刻的隐状态作为已知条件.

​        对于 $t=T-1,T-2,...,1$ 以及 $i=1,2,...,n$，
$$
\beta_t(i)=[\sum_{j=1}^n\beta_{t+1}(j)]a_{ij}b_j(O_{t+1}).
$$
​        特别注意，最后 $t=1$ 时隐状态的分布需要满足初始状态分布概率，所以通过乘 $\pi_i$ 给每个后向概率加权，即：
$$
P(O|M)=\sum_{i=1}^m\pi_ib_i(O_1)\beta_1(i)
$$

​        容易看出，除了迭代方向不同，前向算法和后向算法的思路及迭代过程是一致的，所以它们的计算结果和时间复杂度也应是一致的。



### 2.解码问题

​        已知模型 $M=(A,B,\pi)$ 和观测值序列 $O=\{O_i\}$ ，求最可能产生 $O$ 的隐马尔科夫链

​        问题的本质就是求 $maxP(S|M,O)$。解码问题的解决方法有最大期望值法和维特比方法。

#### 2.1 最大期望值法

​        最大期望值法的思路就是穷举法，即对于每个时刻，计算每个状态出现的条件概率。将每个时刻出现概率最大的状态组合起来，便得到了所求的马尔科夫链。在符号上，定义
$$
\gamma_t(i)=P(S_t=s_i|O,M)
$$
为 $t$ 时刻状态为 $s_i$ 的条件概率。这个概率表面上不好算，实际上可以藉由之前定义的前向概率和后向概率来简化计算。因为 $\alpha_t(i)$ 度量了到时间 $t$ 为止的有关概率，$\beta_t(i)$ 度量了时间 $t$ 之后的有关概率，而在评估问题的前向算法中，已经得到 $P(O|M)=\sum_{i=1}^n\alpha_T(i)$ ，所以用条件概率公式直接计算：
$$
\gamma_t(i)=\frac{\alpha_t(i)\beta_t(i)}{P(O|M)}
$$

$$
i=argmax\gamma_t(i),i=1,2,3,...,n
$$

####2.2 维特比算法

​        维特比算法通过向前迭代来计算观测序列的产生概率，这一点与前向算法相似。该方法的关键思想是：如果 $s_1,s_2,...,s_{k-1},s_k$ 是最可能产生观测序列 $O_1,O_2,...,O_{k-1},O_k$ 的过程，那么 $s_1,s_2,...,s_{k-1}$ 应该是最可能产生 $O_1,O_2,...,O_{k-1}$的过程。定义
$$
\delta_k(i)=max_{(S_1,S_2,...,S_{k-1}\in s)}P(S_1,S_2,...,S_{k-1},S_k=s_i,O_1,O_2,...,O_k).
$$
对于 $i=1,2,...,n$，$k=1$，初始值为
$$
\delta_1(i)=maxP(S_1=s_i,O_1)=\pi_ib_i(O_1)
$$
对于 $j=1,2..,n$ 及 $k=2$，根据上述的关键思想，有
$$
\delta_k(i)=max_{(i)}[a_{ij}b_j(O_k)\delta_{k-1}(i)]
$$
这样，对于观测序列 $O_1,O_2,...,O_T$，只要计算出 $\delta_T(i)$，回溯便可得到最可能产生 $O$ 的马尔科夫序列。



### 3.学习问题

​        已知观测序列 $O=\{O_i\}$ ，求最可能产生 $O$ 的模型 $M=(A,B,\pi)$

​        学习问题的目的和评估问题相同，就是求 $P(O|M)$，此时将模型 $M$ 作为参数调节。目前没有找到全局最优解的方法，但可以通过EM算法（期望最大化）来得到 $P(O|M)$ 的局部最大值，也就是 Baun-Welch方法。为了找出全局最大值，一个明智的策略是使用一系列的起始值来进行最大化，并看看在每种情况下是否能识别出相同的最大值。

####Baun-Welch方法

​        该方法的基本思想如下：

​        ① 在已知条件只有观测序列 $O$，对模型 $M$ 没有任何了解的情况下，先将 $M$ 随机初始化（比如令 $\pi_i=1/n,a_{ij}=1/n,b_j(k)=1/m$），接下来将在初始值的基础上进行优化。

​        ②根据现有的 $M$ 和观测序列 $O$，重新估计 $M$。

​        ③如果 $P(O|M)$ 增加，回到步骤②。不断重复②，直到最后得到最优模型 $M$。

关于模型 $M$ 的初始化，一个较为系统的策略是基于观测分位数的。例如，一个 $m=3$ 的三态HMM，隐状态的取值可以初始化为观测计数的下四分位数、中位数和上四分位数。

$M$ 的具体更新方法如下：

为描述方便，首先定义两个概率。

定义  $\xi_k(i,j)$ 为给定观测值 $O_1,O_2,...,O_T$ 的条件下在时刻 $k$ 位于状态 $s_i$，而在时刻 $k+1$ 位于状态 $s_j$ 的概率，即
$$
\begin{aligned}
\xi_k(i,j) &=P(S_k=s_i,S_{k+1}=s_j|O_1,O_2,...,O_T)\\
           &=\frac{P(S_k=s_i,S_{k+1}=s_j,O_1,O_2,...,O_T)}{P(O_1,O_2,...,O_k)}\\
           &=\frac{P(S_k=s_i,O_1,O_2,...,O_k)a_{ij}b_j(O_{k+1})P(O_{k+2},O_{k+3},...,O_T|S_{k+1}=s_j)}{P(O_1,O_2,...,O_k)}\\
           &=\frac{\alpha_k(i)a_{ij}b_j(O_{k+1})\beta_{k+1}(j)}{\sum_i\sum_j\alpha_k(i)a_{ij}b_j(O_{k+1})\beta_{k+1}(j)}
\end{aligned}
$$
定义  $\gamma_k(i)$ 为给定观测值 $O_1,O_2,...,O_T$ 的条件下，在时刻 $k$ 时，状态 $S_k=s_i$ 的概率，即
$$
\gamma_k(i)=P(S_k=s_i|O_1,O_2,...,O_T)=\frac{P(S_k=s_i,O_1,O_2,...,O_k)}{P(O_1,O_2,...,O_k)}=\frac{\alpha_k(i)\beta_k(i)}{\sum_i\alpha(i)\beta_k(i)}.
$$
以上两式中出现的 $\alpha_k(i),\beta_k(i)$ 已在前文的前向后向算法中定义，所以两个概率都可以用现有的模型直接计算。接下来，将用这两个值来更新模型 $M$ 的参数，具体做法如下：
$$
a_{ij}=P(S_j|S_i)=\frac{从S_i到S_j转移的期望数目}{从S_i中转移出的期望数目}=\frac{\sum_k\xi_k(i,j)}{\sum_k\gamma_k(i)}\\
b_i(o_l)=P(O_i=o_l|S_i)=\frac{S_i中出现o_l的期望数目}{S_i中出现的期望数目}=\frac{\sum_k\xi_k(i,j)}{\sum_(k,O_k=o_l)\gamma_k(i)}\\
\pi_i=P(S_i)=在时刻k=1时在S_i的期望频率=\gamma_1(i)
$$
这样，模型的参数便更新了。通过比较新旧模型的 $P(O|M)$ 来判断是否达到收敛。

​        那么这种方法更新的参数就会达到局部最优解吗？要解释这个方法的有效性，需要用到更多数学理论，笔主尚未理解，所以此处不作证明。



##三、HMM的应用

###3.1 R代码

R语言的程序包提供了上述算法的现成函数，非常方便，下方列举一些基础用法。

```
# 载入HMM程序包
library(HMM)


# 定义一个HMM模型，五个参数依次是隐藏状态空间、观测状态空间、初始分布、转移概率矩阵、发送概率矩阵
hmm = initHMM(S,Sb,startProbs=,transProbs=,emissionProbs=)


# 前向、后向算法函数，返回的是概率对数
f = forward(hmm,w$observation)
b = backward(hmm,w$observation)


# 维特比算法，返回最优的隐状态估计
vit = viterbi(hmm,w$observation)


# Baum-Welch方法，返回模型M的估计
# maxItertion是最大迭代数；delta是临界值，两个P(O|M)的差大于它模型才会更新；pseudoCount用于处理特殊值
bw = baumWelch(hmm,w$observation,maxIteration=,delta=,pseudoCount=)
```

​        

###3.2 现实应用简介

​        此处只介绍HMM在现实中的一大重大应用：语音识别。

​        语音识别的任务就是从音频（可观测序列）中分析出文字（隐马尔科夫链），它可以看作HMM的解码问题，但首先我们需要得到语言产生语音的HMM模型。为此，语音识别的模型训练需要大型的语料库，语料包括音频和对应的汉字，这样就可以使用最大似然估计求解HMM的参数。

​        从直观上讲，语音识别的简要过程描述如下：通过语料库的大量语句，可以计算各个字词之间的转移概率 $A$ ;通过可观察的语音，可以找到很多条对应汉字，计算这些备选概率，就得到发送概率矩阵 $B$，取概率最大的结果就是语音识别的结果。

​       需要说明的是，上述只是HMM在语音识别中应用的一个小场合，真正的语音识别模型应用的方法更多、更复杂，效果也更好。

参考文献
[1]《贝叶斯数据分析——基于R与Python的实现》，吴喜之
[2]《Hidden Markov Models for Time Series An Introduction Using R》，Walter Zucchini,lain L.MacDonald
[3]《语音合成技术综述及研究现状》，魏伟华
[4]《贝叶斯分析》，韦来生
